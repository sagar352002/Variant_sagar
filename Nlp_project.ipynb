{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef4b5315",
   "metadata": {},
   "source": [
    "- Imdb Movie sentiment analysis\n",
    "- Text Generation with Long Short-Term Memory (LSTM) Networks: Create a text generation system using LSTM-based RNNs that \n",
    "    can generate coherent and contextually relevant text \n",
    "    based on a given input or prompt.\n",
    "- Language Translation with Sequence-to-Sequence Models: Implement a language translation system using RNN-based \n",
    "sequence-to-sequence models, such as Encoder-Decoder architecture with Long Short-Term Memory (LSTM) cells, \n",
    "capable of translating text between different languages.\n",
    "- Sequence-to-Sequence with Attention Model: Implement a sequence-to-sequence model with attention mechanisms for abstractive text summarization. This model serves as the base architecture for generating summaries from the input text, allowing the system to focus on relevant parts of the document while generating summaries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d664672f",
   "metadata": {},
   "source": [
    "# NLP imdb Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f25540f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89aceda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc16f2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6455d8f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "positive    25000\n",
       "negative    25000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts() # Balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1921211f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d24e405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e046229",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a6a0683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0929a73b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49582, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b38f2c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=df.sample(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00fb8426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bfece8",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4720d8b4",
   "metadata": {},
   "source": [
    "# Lower Casing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26aea383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03ebf2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['review'][3].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e11bb09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['review'].str.lower() # for entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32d443aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review']=df['review'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e319484e",
   "metadata": {},
   "source": [
    "# Remove html tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c3d1916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex (regular expression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6eae26de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def removal_html_tag(text):\n",
    "    fun=re.compile('<.*?>')\n",
    "    return fun.sub(r'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e54a9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['review'].apply(removal_html_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8083d901",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review']=df['review'].apply(removal_html_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1036080f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['review'][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dbddf8",
   "metadata": {},
   "source": [
    " ## url removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6979f3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def removal_url(text):\n",
    "    fun=re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return fun.sub(r'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8a8ee7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review']=df['review'].apply(removal_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8da2790",
   "metadata": {},
   "source": [
    "## remove punctuation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bde2d205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e66f7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude=string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90a6ace4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removal_punc1(text):\n",
    "    return text.translate(str.maketrans('', '', exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a60faa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review']=df['review'].apply(removal_punc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1204a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28304</th>\n",
       "      <td>the tempest has been interpreted in many diffe...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48477</th>\n",
       "      <td>young couple on the road minding their own bus...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29822</th>\n",
       "      <td>at least for me and rather unexpected as subje...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46982</th>\n",
       "      <td>i agree with the above comment i love the real...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24613</th>\n",
       "      <td>great job was very exciting and had great stun...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "28304  the tempest has been interpreted in many diffe...  positive\n",
       "48477  young couple on the road minding their own bus...  negative\n",
       "29822  at least for me and rather unexpected as subje...  positive\n",
       "46982  i agree with the above comment i love the real...  positive\n",
       "24613  great job was very exciting and had great stun...  positive"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb24a559",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa2f55a5",
   "metadata": {},
   "source": [
    "## Spelling correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a582cb0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The War is on The beside of room'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob # dont do inefficent solution\n",
    "\n",
    "incorrect='The Car is on The bkside of rood'\n",
    "word=TextBlob(incorrect)\n",
    "word.correct().string\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a2da7c",
   "metadata": {},
   "source": [
    "## removing stop word\n",
    "# we cant remove stop word in pos tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "93a35456",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "sw_list=stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee8324ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Sagar\n",
      "[nltk_data]     Kumar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Sagar\n",
      "[nltk_data]     Kumar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download NLTK stopwords data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "74ed3dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_stopwords(text):\n",
    "#     new_text=[]\n",
    "#     for word in text.split():\n",
    "#         if word in stopwords.words('english'):\n",
    "#             new_text.append('')\n",
    "#         else:\n",
    "#             new_text.append(word)\n",
    "#     x=new_text[:]\n",
    "#     new_text.clear()\n",
    "#     return \" \".join(x)\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    new_text = []\n",
    "    for word in text.split():\n",
    "        if word not in stop_words:\n",
    "            new_text.append(word)\n",
    "    return \" \".join(new_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1acbc13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "400ce612",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review']=df['review'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e9356036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import emoji\n",
    "\n",
    "# def convert_emojis(text):\n",
    "#     def replace_emoji(match):\n",
    "#         emoji_code = match.group(0)\n",
    "#         emoji_text = emoji.demojize(emoji_code)\n",
    "#         return emoji_text\n",
    "\n",
    "#     # Regular expression to match emojis\n",
    "#     emoji_regex = r'[\\U0001F300-\\U0001F5FF\\U0001F600-\\U0001F64F\\U0001F680-\\U0001F6FF\\U0001F700-\\U0001F77F\\U0001F780-\\U0001F7FF\\U0001F800-\\U0001F8FF\\U0001F900-\\U0001F9FF\\U0001FA00-\\U0001FA6F\\U0001FA70-\\U0001FAFF\\U00002702-\\U000027B0\\U00002639\\U00002640\\U00002648\\U0000264F\\U00002653\\U0001F170-\\U0001F251\\U0001F600-\\U0001F64F\\U0001F300-\\U0001F5FF\\U0001F680-\\U0001F6FF\\U0001F700-\\U0001F77F\\U0001F780-\\U0001F7FF\\U0001F800-\\U0001F8FF\\U0001F900-\\U0001F9FF\\U0001FA00-\\U0001FA6F\\U0001FA70-\\U0001FAFF\\U00002702-\\U000027B0\\U00002639\\U00002640\\U00002648\\U0000264F\\U00002653\\U0001F170-\\U0001F251]+'\n",
    "\n",
    "#     # Replace emojis with their text representations\n",
    "#     result_text = emoji.demojize(text)\n",
    "#     return result_text\n",
    "\n",
    "# # Example usage\n",
    "\n",
    "# df['review']=df['review'].apply(convert_emojis)\n",
    "import emoji\n",
    "import re\n",
    "\n",
    "# Compile regex pattern for emojis\n",
    "emoji_regex = re.compile(r'[\\U0001F300-\\U0001F5FF\\U0001F600-\\U0001F64F\\U0001F680-\\U0001F6FF\\U0001F700-\\U0001F77F\\U0001F780-\\U0001F7FF\\U0001F800-\\U0001F8FF\\U0001F900-\\U0001F9FF\\U0001FA00-\\U0001FA6F\\U0001FA70-\\U0001FAFF\\U00002702-\\U000027B0\\U00002639\\U00002640\\U00002648\\U0000264F\\U00002653\\U0001F170-\\U0001F251\\U0001F600-\\U0001F64F\\U0001F300-\\U0001F5FF\\U0001F680-\\U0001F6FF\\U0001F700-\\U0001F77F\\U0001F780-\\U0001F7FF\\U0001F800-\\U0001F8FF\\U0001F900-\\U0001F9FF\\U0001FA00-\\U0001FA6F\\U0001FA70-\\U0001FAFF\\U00002702-\\U000027B0\\U00002639\\U00002640\\U00002648\\U0000264F\\U00002653\\U0001F170-\\U0001F251]+')\n",
    "\n",
    "def convert_emojis(text):\n",
    "    # Replace emojis with their text representations\n",
    "    result_text = emoji.demojize(text)\n",
    "    return result_text\n",
    "\n",
    "# Example usage\n",
    "df['review'] = df['review'].apply(convert_emojis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d377ab24",
   "metadata": {},
   "source": [
    "# Remove emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d1a6bf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "\n",
    "# def remove_emojis(text):\n",
    "#     \"\"\"\n",
    "#     Function to remove emojis from the input text.\n",
    "    \n",
    "#     Parameters:\n",
    "#         text (str): The input text from which emojis will be removed.\n",
    "    \n",
    "#     Returns:\n",
    "#         str: The text with emojis removed.\n",
    "#     \"\"\"\n",
    "#     # Define regex pattern to match emojis\n",
    "#     emoji_pattern = re.compile(\"[\"\n",
    "#                                u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "#                                u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "#                                u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "#                                u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "#                                u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "#                                u\"\\U00002702-\\U000027B0\"\n",
    "#                                u\"\\U00002702-\\U000027B0\"\n",
    "#                                u\"\\U000024C2-\\U0001F251\"\n",
    "#                                u\"\\U0001f926-\\U0001f937\"\n",
    "#                                u\"\\U00010000-\\U0010ffff\"\n",
    "#                                u\"\\u2640-\\u2642\"\n",
    "#                                u\"\\u2600-\\u2B55\"\n",
    "#                                u\"\\u200d\"\n",
    "#                                u\"\\u23cf\"\n",
    "#                                u\"\\u23e9\"\n",
    "#                                u\"\\u231a\"\n",
    "#                                u\"\\ufe0f\"  # dingbats\n",
    "#                                u\"\\u3030\"\n",
    "#                                \"]+\", flags=re.UNICODE)\n",
    "    \n",
    "#     # Remove emojis from the text\n",
    "#     text_without_emojis = emoji_pattern.sub(r'', text)\n",
    "    \n",
    "#     return text_without_emojis\n",
    "\n",
    "# # Example usage:\n",
    "# text_with_emojis = \"Hello! 😀 This is a sample text with emojis! 🚀🎉\"\n",
    "# text_without_emojis = remove_emojis(text_with_emojis)\n",
    "# print(text_without_emojis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a5dec939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['review']=df['review'].apply(remove_emojis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e6a988",
   "metadata": {},
   "source": [
    "## chat word treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "db9caf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "slang=pd.read_csv(\"slangs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "76ca7dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def csv_to_dict(csv_file):\n",
    "    data_dict = {}\n",
    "    with open(csv_file, 'r', newline='', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)  # Skip header if present\n",
    "        for row in reader:\n",
    "            data_dict[row[0]] = row[1]\n",
    "    return data_dict\n",
    "\n",
    "# Example usage\n",
    "chat_words = csv_to_dict('slangs.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "de984f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_conversion(text):\n",
    "    new_text=[]\n",
    "    for w in text.split():\n",
    "        if w.upper() in  chat_words:\n",
    "            new_text.append(chat_words[w.upper()])\n",
    "        else:\n",
    "            new_text.append(w)\n",
    "    return \" \".join(new_text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "84e718a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review']=df['review'].apply(chat_conversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "997caeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['review'][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ac076ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['sentiment']\n",
    "x=df.iloc[:,0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f348e86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y=label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f9a83951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "59bacf7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sagar Kumar\\AppData\\Local\\Temp\\ipykernel_23156\\2058777203.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x['review'] = x['review'].apply(stem_sentence)\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# from nltk.stem import PorterStemmer\n",
    "# from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "\n",
    "# # Initialize the Porter Stemmer\n",
    "# stemmer = PorterStemmer()\n",
    "\n",
    "# # Define a function to apply stemming to a sentence\n",
    "# def stem_sentence(sentence):\n",
    "#     tokens = word_tokenize(sentence)  # Tokenize the sentence\n",
    "#     stemmed_tokens = [stemmer.stem(token) for token in tokens]  # Stem each token\n",
    "#     return \" \".join(stemmed_tokens)  # Join stemmed tokens back into a sentence\n",
    "\n",
    "# # Apply stemming to the 'text' column using the apply function\n",
    "# x = x['review'].apply(stem_sentence)\n",
    "\n",
    "import pandas as pd\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Initialize the Porter Stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Define a function to apply stemming to a sentence\n",
    "def stem_sentence(sentence):\n",
    "    return \" \".join([stemmer.stem(word) for word in word_tokenize(sentence)])\n",
    "\n",
    "# Apply stemming to the 'review' column using the apply function\n",
    "x['review'] = x['review'].apply(stem_sentence)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "41eecb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pd.DataFrame(x,columns=['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eb496705",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e6c9baa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39665, 1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4d647caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39665, 10000)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying BoW\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features=10000)\n",
    "X_train_bow = cv.fit_transform(X_train['review']).toarray()\n",
    "X_test_bow = cv.transform(X_test['review']).toarray()\n",
    "X_train_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "426259de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7010184531612382"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "\n",
    "gnb.fit(X_train_bow,y_train)\n",
    "GaussianNB()\n",
    "y_pred = gnb.predict(X_test_bow)\n",
    "\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e3a3cf6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4356,  677],\n",
       "       [2288, 2596]], dtype=int64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b04f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# # Initialize classifiers\n",
    "# classifiers = {\n",
    "#     \"Naive Bayes\": MultinomialNB(),\n",
    "#     \"Logistic Regression\": LogisticRegression(),\n",
    "#     \"Random Forest\": RandomForestClassifier(),\n",
    "    \n",
    "# }\n",
    "\n",
    "# # Calculate and print accuracy scores for each classifier\n",
    "# for name, clf in classifiers.items():\n",
    "#     clf.fit(X_train_bow, y_train)\n",
    "#     y_pred = clf.predict(X_test_bow)\n",
    "#     accuracy = accuracy_score(y_test, y_pred)\n",
    "#     print(f\"{name} Accuracy: {accuracy}\")\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from multiprocessing import Process, Manager\n",
    "\n",
    "# Function to train and predict for a classifier\n",
    "def train_and_predict(clf, X_train, y_train, X_test, y_test, result_dict):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    result_dict[clf.__class__.__name__] = accuracy\n",
    "\n",
    "# Initialize classifiers\n",
    "classifiers = [\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(),\n",
    "    RandomForestClassifier(),\n",
    "]\n",
    "\n",
    "# Dictionary to store accuracy scores\n",
    "manager = Manager()\n",
    "accuracy_scores = manager.dict()\n",
    "\n",
    "# Train and predict for each classifier concurrently\n",
    "processes = []\n",
    "for clf in classifiers:\n",
    "    p = Process(target=train_and_predict, args=(clf, X_train_bow, y_train, X_test_bow, y_test, accuracy_scores))\n",
    "    p.start()\n",
    "    processes.append(p)\n",
    "\n",
    "# Wait for all processes to finish\n",
    "for p in processes:\n",
    "    p.join()\n",
    "\n",
    "# Print accuracy scores\n",
    "for clf_name, accuracy in accuracy_scores.items():\n",
    "    print(f\"{clf_name} Accuracy: {accuracy}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056d3f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Featurees Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472dffa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_features=10000)\n",
    "\n",
    "X_train_bow = cv.fit_transform(X_train['review']).toarray()\n",
    "X_test_bow = cv.transform(X_test['review']).toarray()\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf.fit(X_train_bow,y_train)\n",
    "y_pred = rf.predict(X_test_bow)\n",
    "accuracy_score(y_test,y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c91f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize CountVectorizer\n",
    "cv = CountVectorizer(max_features=10000)\n",
    "\n",
    "# Transform the training and testing data into bag-of-words representations\n",
    "X_train_bow = cv.fit_transform(X_train['review'])\n",
    "X_test_bow = cv.transform(X_test['review'])\n",
    "\n",
    "# Initialize and train Naive Bayes classifier\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_bow, y_train)\n",
    "\n",
    "# Predict using Naive Bayes classifier\n",
    "nb_pred = nb.predict(X_test_bow)\n",
    "\n",
    "# Calculate accuracy for Naive Bayes classifier\n",
    "nb_accuracy = accuracy_score(y_test, nb_pred)\n",
    "print(\"Naive Bayes Accuracy:\", nb_accuracy)\n",
    "\n",
    "# Initialize and train Logistic Regression classifier\n",
    "lr = LogisticRegression(max_iter=1000)  # Increase max_iter if needed\n",
    "lr.fit(X_train_bow, y_train)\n",
    "\n",
    "# Predict using Logistic Regression classifier\n",
    "lr_pred = lr.predict(X_test_bow)\n",
    "\n",
    "# Calculate accuracy for Logistic Regression classifier\n",
    "lr_accuracy = accuracy_score(y_test, lr_pred)\n",
    "print(\"Logistic Regression Accuracy:\", lr_accuracy)\n",
    "\n",
    "# Initialize and train Random Forest classifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_bow, y_train)\n",
    "\n",
    "# Predict using Random Forest classifier\n",
    "rf_pred = rf.predict(X_test_bow)\n",
    "\n",
    "# Calculate accuracy for Random Forest classifier\n",
    "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "print(\"Random Forest Accuracy:\", rf_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915fba0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize CountVectorizer\n",
    "cv = CountVectorizer(max_features=12000)\n",
    "\n",
    "# Transform the training and testing data into bag-of-words representations\n",
    "X_train_bow = cv.fit_transform(X_train['review'])\n",
    "X_test_bow = cv.transform(X_test['review'])\n",
    "\n",
    "# Initialize classifiers\n",
    "nb = MultinomialNB()\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Fit classifiers\n",
    "nb.fit(X_train_bow, y_train)\n",
    "lr.fit(X_train_bow, y_train)\n",
    "rf.fit(X_train_bow, y_train)\n",
    "\n",
    "# Create VotingClassifier\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('nb', nb), ('lr', lr), ('rf', rf)],\n",
    "    voting='hard'  # Use majority voting\n",
    ")\n",
    "\n",
    "# Fit VotingClassifier\n",
    "voting_clf.fit(X_train_bow, y_train)\n",
    "\n",
    "# Predict using VotingClassifier\n",
    "voting_pred = voting_clf.predict(X_test_bow)\n",
    "\n",
    "# Calculate accuracy for VotingClassifier\n",
    "voting_accuracy = accuracy_score(y_test, voting_pred)\n",
    "print(\"Voting Classifier Accuracy:\", voting_accuracy)\n",
    "\n",
    "\n",
    "# Calculate accuracy f\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe6743a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize CountVectorizer\n",
    "cv = CountVectorizer(ngram_range=(1,2), max_features=5000)\n",
    "\n",
    "# Transform the training and testing data into bag-of-words representations\n",
    "X_train_bow = cv.fit_transform(X_train['review']).toarray()\n",
    "X_test_bow = cv.transform(X_test['review']).toarray()\n",
    "\n",
    "# Initialize and train Naive Bayes classifier\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_bow, y_train)\n",
    "\n",
    "# Predict using Naive Bayes classifier\n",
    "nb_pred = nb.predict(X_test_bow)\n",
    "\n",
    "# Calculate accuracy for Naive Bayes classifier\n",
    "nb_accuracy = accuracy_score(y_test, nb_pred)\n",
    "print(\"Naive Bayes Accuracy:\", nb_accuracy)\n",
    "\n",
    "# Initialize and train Logistic Regression classifier\n",
    "lr = LogisticRegression(max_iter=1000)  # Increase max_iter if needed\n",
    "lr.fit(X_train_bow, y_train)\n",
    "\n",
    "# Predict using Logistic Regression classifier\n",
    "lr_pred = lr.predict(X_test_bow)\n",
    "\n",
    "# Calculate accuracy for Logistic Regression classifier\n",
    "lr_accuracy = accuracy_score(y_test, lr_pred)\n",
    "print(\"Logistic Regression Accuracy:\", lr_accuracy)\n",
    "\n",
    "# Initialize and train Random Forest classifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_bow, y_train)\n",
    "\n",
    "# Predict using Random Forest classifier\n",
    "rf_pred = rf.predict(X_test_bow)\n",
    "\n",
    "# Calculate accuracy for Random Forest classifier\n",
    "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "print(\"Random Forest Accuracy:\", rf_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84956faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize CountVectorizer\n",
    "cv = CountVectorizer(ngram_range=(1,2), max_features=5000)\n",
    "\n",
    "# Transform the training and testing data into bag-of-words representations\n",
    "X_train_bow = cv.fit_transform(X_train['review'])\n",
    "X_test_bow = cv.transform(X_test['review'])\n",
    "\n",
    "# Initialize classifiers\n",
    "nb = MultinomialNB()\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Fit classifiers\n",
    "nb.fit(X_train_bow, y_train)\n",
    "lr.fit(X_train_bow, y_train)\n",
    "rf.fit(X_train_bow, y_train)\n",
    "\n",
    "# Create VotingClassifier\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('nb', nb), ('lr', lr), ('rf', rf)],\n",
    "    voting='hard'  # Use majority voting\n",
    ")\n",
    "\n",
    "# Fit VotingClassifier\n",
    "voting_clf.fit(X_train_bow, y_train)\n",
    "\n",
    "# Predict using VotingClassifier\n",
    "voting_pred = voting_clf.predict(X_test_bow)\n",
    "\n",
    "# Calculate accuracy for VotingClassifier\n",
    "voting_accuracy = accuracy_score(y_test, voting_pred)\n",
    "print(\"Voting Classifier Accuracy:\", voting_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8de5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# tfidf = TfidfVectorizer()\n",
    "# X_train_tfidf = tfidf.fit_transform(X_train['review']).toarray()\n",
    "# X_test_tfidf = tfidf.transform(X_test['review'])\n",
    "# rf = RandomForestClassifier()\n",
    "\n",
    "# rf.fit(X_train_tfidf,y_train)\n",
    "# y_pred = rf.predict(X_test_tfidf)\n",
    "\n",
    "# accuracy_score(y_test,y_pred)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize TfidfVectorizer with n_jobs parameter\n",
    "tfidf = TfidfVectorizer(n_jobs=-1)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train['review'])\n",
    "X_test_tfidf = tfidf.transform(X_test['review'])\n",
    "\n",
    "# Initialize RandomForestClassifier with n_jobs parameter\n",
    "rf = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "# Fit the model and make predictions\n",
    "rf.fit(X_train_tfidf, y_train)\n",
    "y_pred = rf.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6343fbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Initialize classifiers\n",
    "classifiers = {\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "}\n",
    "\n",
    "# Calculate and print accuracy scores for each classifier\n",
    "for name, clf in classifiers.items():\n",
    "    clf.fit(X_train_tfidf, y_train)\n",
    "    y_pred = clf.predict(X_test_tfidf)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{name} Accuracy: {accuracy}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7452bdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voting sTacking Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4614c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Assuming you have X_train_tfidf, X_test_tfidf, y_train, and y_test defined\n",
    "\n",
    "# Initialize base classifiers\n",
    "base_classifiers = {\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "}\n",
    "\n",
    "# Initialize meta-classifier\n",
    "meta_classifier = KNeighborsClassifier()\n",
    "\n",
    "# Train base classifiers and make predictions\n",
    "predictions = {}\n",
    "for name, clf in base_classifiers.items():\n",
    "    clf.fit(X_train_tfidf, y_train)\n",
    "    predictions[name] = clf.predict(X_test_tfidf).reshape(-1, 1)  # Reshape predictions\n",
    "\n",
    "# Stack predictions horizontally to create new features\n",
    "X_stacked = np.hstack(list(predictions.values()))\n",
    "\n",
    "# Train meta-classifier using stacked predictions\n",
    "meta_classifier.fit(X_stacked, y_test)\n",
    "\n",
    "# Make stacked predictions for test data\n",
    "stacked_predictions = np.hstack(list(predictions.values()))\n",
    "\n",
    "# Evaluate meta-classifier accuracy\n",
    "meta_accuracy = accuracy_score(y_test, meta_classifier.predict(stacked_predictions))\n",
    "print(f\"Stacked Classifier Accuracy: {meta_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aebb9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Initialize classifiers\n",
    "classifiers = [\n",
    "    (\"Naive Bayes\", MultinomialNB()),\n",
    "    (\"Logistic Regression\", LogisticRegression()),\n",
    "    (\"Random Forest\", RandomForestClassifier())\n",
    "]\n",
    "\n",
    "# Create VotingClassifier\n",
    "voting_clf = VotingClassifier(estimators=classifiers, voting='hard', n_jobs=-1)\n",
    "\n",
    "# Train VotingClassifier\n",
    "voting_clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = voting_clf.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Voting Classifier Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3cb9b3",
   "metadata": {},
   "source": [
    "# Tokeniazation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804ee5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import spacy\n",
    "\n",
    "# # Load the English tokenizer\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# # Define a function to tokenize text\n",
    "# def tokenize_text(text):\n",
    "#     doc = nlp(text)\n",
    "#     return [token.text for token in doc]\n",
    "\n",
    "# # Apply tokenization on the 'text' column using the apply function\n",
    "# x = x.apply(tokenize_text)\n",
    "\n",
    "# # Display the DataFrame with tokenized text\n",
    "# print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0538b76a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcd3cef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0103eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09dd6ec",
   "metadata": {},
   "source": [
    "# Text Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a30ee75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "# # Initialize the TF-IDF vectorizer\n",
    "# tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# # Fit and transform the documents to TF-IDF matrix\n",
    "# tfidf_matrix = tfidf_vectorizer.fit_transform(X)\n",
    "\n",
    "# # Convert the TF-IDF matrix to a DataFrame (optional)\n",
    "# import pandas as pd\n",
    "# tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "# # Display the TF-IDF matrix\n",
    "# print(tfidf_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc751556",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f9a08b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
